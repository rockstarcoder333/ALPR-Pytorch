{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "The autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload\n"
    }
   ],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import pandas as pd\n",
    "from PIL import Image, ImageDraw\n",
    "from torchvision import transforms\n",
    "import mmcv\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from model import create_model\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../model.pth'\n",
    "video_path = './video.mp4'\n",
    "threshold = 0.1\n",
    "\n",
    "model = create_model()\n",
    "checkpoint = torch.load(model_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model'])\n",
    "_ = model.eval()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred(image, model):\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "\n",
    "    input_tensor = preprocess(image)\n",
    "    input_batch = input_tensor.unsqueeze(0)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        input_batch = input_batch.to('cuda')\n",
    "        model.to('cuda')\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_batch)['out'][0]\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Tracking frame: 302"
    }
   ],
   "source": [
    "frames_tracked = []\n",
    "\n",
    "video = mmcv.VideoReader(video_path)\n",
    "frames = [Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)) for frame in video]\n",
    "\n",
    "for i, frame in enumerate(frames):\n",
    "    print('\\rTracking frame: {}'.format(i + 1), end='')\n",
    "\n",
    "    output = pred(frame, model)\n",
    "\n",
    "    output = (output > threshold).type(torch.IntTensor)\n",
    "    output = output.cpu().numpy()[0]\n",
    "\n",
    "    result = np.where(output > 0)\n",
    "    coords = list(zip(result[0], result[1]))\n",
    "\n",
    "    for cord in coords:\n",
    "        frame.putpixel((cord[1], cord[0]), (255, 0, 0))\n",
    "\n",
    "    frames_tracked.append(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = frames_tracked[0].size\n",
    "fourcc = cv2.VideoWriter_fourcc(*'FMP4')    \n",
    "video_tracked = cv2.VideoWriter('video_tracked.mp4', fourcc, 25.0, dim)\n",
    "for frame in frames_tracked:\n",
    "    video_tracked.write(cv2.cvtColor(np.array(frame), cv2.COLOR_RGB2BGR))\n",
    "video_tracked.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}